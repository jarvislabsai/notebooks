{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b7e672-d6ad-4bdc-ab9a-9f36ef5f9963",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir Dreambooth\n",
    "!cd Dreambooth\n",
    "!mkdir input_path output_path class_path  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5074039e-6020-459a-ba50-bb8a78d9dd44",
   "metadata": {},
   "source": [
    "Install the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f8b2ed-e613-4126-9c4d-73604bbb6067",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://github.com/ShivamShrirao/diffusers/raw/main/examples/dreambooth/train_dreambooth.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911e30d8-669e-4fc1-bb94-5b20657586a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcacc095-c5bb-4d73-83d4-f375c59d3489",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd71e462-3df2-4820-b748-f04548ba92f2",
   "metadata": {},
   "source": [
    "Huggingface login"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d09ede4-f19f-4c3f-bc2a-2429a55f2eeb",
   "metadata": {},
   "source": [
    "Load the input images in /home/Dreambooth/input_path folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c73e5a-76b4-4e4c-994f-5e73e225a736",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a concepts_list with their paths\n",
    "\n",
    "concepts_list = [\n",
    "    {\n",
    "        \"instance_prompt\":      \"photo of kak person\",#kak is the keyword/token of our images\n",
    "        \"class_prompt\":         \"photo of a person\",\n",
    "        \"instance_data_dir\":    \"/home/Dreambooth/input_path\",\n",
    "        \"class_data_dir\":       \"/home/Dreambooth/class_path\"\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e8680c-8165-4d74-adfe-0b6453b1b7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "\n",
    "with open(\"concepts_list.json\", \"w\") as f:\n",
    "    json.dump(concepts_list, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19d7266-459b-41b7-a77d-104656bf8337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training\n",
    "\n",
    "!accelerate launch train_dreambooth.py \\\n",
    "  --pretrained_model_name_or_path=\"stabilityai/stable-diffusion-2-base\" \\\n",
    "  --pretrained_vae_name_or_path=\"stabilityai/sd-vae-ft-mse\" \\\n",
    "  --output_dir=\"/home/Dreambooth/output_path\" \\\n",
    "  --revision=\"fp16\" \\\n",
    "  --with_prior_preservation --prior_loss_weight=1.0 \\\n",
    "  --seed=1337 \\\n",
    "  --resolution=512 \\\n",
    "  --train_batch_size=1 \\\n",
    "  --train_text_encoder \\\n",
    "  --mixed_precision=\"fp16\" \\\n",
    "  --use_8bit_adam \\\n",
    "  --gradient_accumulation_steps=1 \\\n",
    "  --learning_rate=1e-6 \\\n",
    "  --lr_scheduler=\"constant\" \\\n",
    "  --lr_warmup_steps=0 \\\n",
    "  --num_class_images=50 \\\n",
    "  --sample_batch_size=4 \\\n",
    "  --max_train_steps=1500 \\\n",
    "  --save_interval=500 \\\n",
    "  --save_sample_prompt=\"photo of kak person\" \\\n",
    "  --concepts_list=\"concepts_list.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b2e8e1-987f-4a98-963c-64ce16aeff5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHTS_DIR=\"/home/Dreambooth/output_path/1500\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f4e552-854b-49aa-bf3b-d37c3fde7edc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f7a6619-73cd-4c16-9ef7-94f299208c4c",
   "metadata": {},
   "source": [
    "Creating Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f127d1-d055-43ec-b925-a34b09ae0cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import autocast\n",
    "from diffusers import StableDiffusionPipeline, DDIMScheduler\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d035eb-e5f0-41a5-af1b-1598db250233",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    pipe\n",
    "except NameError:\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(\n",
    "        WEIGHTS_DIR,\n",
    "        torch_dtype=torch.float16,\n",
    "    ).to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35faffb3-f2ea-438b-89be-bb764ce8ec7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ce9dfc-c8d8-4197-96d4-5a80964977d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a764e78-b4cc-47e6-bbb5-daab27492744",
   "metadata": {},
   "source": [
    "Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40431d0d-e14a-4295-a2da-1f45a4364ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33156a35-f5e1-457e-b9cb-2ad183cec0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(prompt, num_samples):\n",
    "    all_images = [] \n",
    "    images = pipe(prompt, num_images_per_prompt=num_samples, num_inference_steps=50, guidance_scale=7.5).images\n",
    "    all_images.extend(images)\n",
    "    return all_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ebb7b3-3904-4c42-a493-119816139a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            prompt = gr.Textbox(label=\"prompt\")\n",
    "            samples = gr.Slider(label=\"Samples\",value=1)\n",
    "            run = gr.Button(value=\"Run\")\n",
    "        with gr.Column():\n",
    "            gallery = gr.Gallery(show_label=False)\n",
    "\n",
    "    run.click(inference, inputs=[prompt,samples], outputs=gallery)\n",
    "    gr.Examples([[\"a photo of vish person as captain america\", 1,1]], [prompt,samples], gallery, inference, cache_examples=False)\n",
    "\n",
    "\n",
    "demo.launch(server_name=\"0.0.0.0\",server_port=6006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3bfd1e-15f2-43d8-a811-cdbe09580d18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
