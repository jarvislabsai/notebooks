{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Langchain, OpenAI and Chroma to build a Question Answering System based on FastAPI docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain.document_loaders import UnstructuredURLLoader\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download sitemap.xml file from a website and extract all the links\n",
    "def get_links(url):\n",
    "    url = f'{url}/sitemap.xml'\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'lxml')\n",
    "        links = [link.text for link in soup.find_all('loc')]\n",
    "        return links\n",
    "    else:\n",
    "        print(f'Error: {response.status_code}')\n",
    "        return None\n",
    "    \n",
    "# Download the contents of a webpage given its urls\n",
    "def download_pages(urls: list[str]):\n",
    "    data = UnstructuredURLLoader(urls=urls).load()\n",
    "    return data    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load all the environment variables like OpenAI API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### URL of FastAPI docs, change this to any other website you want.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_url = 'https://fastapi.tiangolo.com/'\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Get all the links from the fastapi website, and download all the content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vishnusubramanian/Documents/randomprojects/explorelangchain/.venv/lib/python3.9/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "links = get_links(base_url)\n",
    "docs = download_pages(links[1:3])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split all the documents into chunks of 1000 tokens, convert them into embeddings using OpenAI embeddings and store them in a vector store Chroma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
    "split_docs = text_splitter.split_documents(docs)\n",
    "embeddings = OpenAIEmbeddings()\n",
    "db = Chroma.from_documents(collection_name='webdata',\n",
    "                           documents=split_docs,\n",
    "                           embedding=embeddings,persist_directory='index_data')\n",
    "db.persist()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "db = Chroma(collection_name='webdata',\n",
    "            embedding_function=embeddings,\n",
    "            persist_directory='index_data/')\n",
    "query = \"What is async code?\"\n",
    "\n",
    "# Fetch similar docs\n",
    "docs = db.similarity_search(query,k=3)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Language model along with the fasapi docs to explore more. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm = ChatOpenAI(model_name='gpt-3.5-turbo',temperature=0.0)\n",
    "qa = RetrievalQA.from_chain_type(llm=llm, \n",
    "                                 retriever=db.as_retriever(),\n",
    "                                 chain_type='stuff')\n",
    "qa.run('How is async used in fastai')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hope You found it useful."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
